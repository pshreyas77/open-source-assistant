NVIDIA_API_KEY present: True
GOOGLE_API_KEY present: True

--- Testing NVIDIA LLM Initialization ---
C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\langchain_core\_api\deprecation.py:27: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.
  from pydantic.v1.fields import FieldInfo as FieldInfoV1
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
[OK] NVIDIA LLM initialized successfully
Attempting invocation...
Invocation success: content='Hello! How can I assist you today?' additional_kwargs={} response_metadata={'role': 'assistant', 'content': 'Hello! How can I assist you today?', 'token_usage': {'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens': 9}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'} id='run--70816797-64fe-43f2-8960-a5f04e19c49e-0' usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20} role='assistant'

--- Testing Google Gemini LLM Initialization ---
[OK] Google Gemini LLM initialized successfully
Attempting invocation...
Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-1.5-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..
Invocation failed: 404 models/gemini-1.5-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.
Traceback (most recent call last):
  File "C:\Users\shrey\.gemini\antigravity\scratch\open-source-assistant\reproduce_issue.py", line 52, in <module>
    response = llm.invoke("Hello")
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\langchain_google_genai\chat_models.py", line 961, in _generate
    response: GenerateContentResponse = _chat_with_retry(
                                        ~~~~~~~~~~~~~~~~^
        request=request,
        ^^^^^^^^^^^^^^^^
    ...<2 lines>...
        metadata=self.default_metadata,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\langchain_google_genai\chat_models.py", line 196, in _chat_with_retry
    return _chat_with_retry(**kwargs)
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\concurrent\futures\_base.py", line 443, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\concurrent\futures\_base.py", line 395, in __get_result
    raise self._exception
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\langchain_google_genai\chat_models.py", line 194, in _chat_with_retry
    raise e
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\langchain_google_genai\chat_models.py", line 178, in _chat_with_retry
    return generation_method(**kwargs)
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
        exc,
    ...<6 lines>...
        timeout,
    )
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "C:\Users\shrey\AppData\Local\Programs\Python\Python314\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.NotFound: 404 models/gemini-1.5-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.
